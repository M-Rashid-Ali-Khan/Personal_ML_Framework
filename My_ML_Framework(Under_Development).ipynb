{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1sHr3WYcbvuGAsS303KwvBK1x1INT8kII","authorship_tag":"ABX9TyNTO0faawqCw8Gr3ImQVfUP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["**Understanding Neural Networks Math using numpy (CNN)**\n"],"metadata":{"id":"-8_vLntLDfY5"}},{"cell_type":"markdown","source":["Working:\n","*   Input\n","*   Convolution\n","*   Fully connected layer:\n","    1.   Linear Transform\n","    2.   Non-Linear Transform\n","*   Output\n","*   Error\n","*   Backward propagation\n","\n","Convolution:\n","*   Z = x*f\n","*   If x is (n,n) and f is (m,m) then Z is (n-m+1,n-m+1)\n","\n","Linear Transformation:\n","*   w.T * x + b\n","\n","Non-Linear Transformation:\n","*   Sigmoid eq: 1/(1+e^-x)\n","\n","Error:\n","*   ((Y-Yo)^2)/2 Yo is output and Y is truth\n","\n","Parameter fine tuning:\n","*   new_parameter = old_parameter - (learning_rate*gradient_of_parameter)\n","*   learning_rate is constant\n","*   gradient is calculated by backward propagation\n","\n","Backward Propagation:\n","*   gradient is d(e)/d(w) e-error w-weight\n","*   Using Chain Rule.\n","\n","Queries:\n","*   Why take transpose?\n","*   Types of activation function\n","*   I think what they have done is that they created diffeernt weights for every image and its patches. And they iterated to get a good epoch. In this way, every image is providing an inependent path. But wait, should'nt each neuron from one layer be interconned to every other layer. I think I am missing pieces of puzzle.   \n","*   I think I am using the reinforcement learning paradigm but the problem is a supervised binary classification.\n","\n","OUR MODEL:\n","*   Input - Batch 1\n","*   Comvolution layer\n","*   Sigmoid layer\n","*   Flatten Layer - 2d feature maps to 1d feature maps\n","*   Connected layer - Linear\n","*   Sigmoid\n","*   Error\n","*   Backpropogation\n","*   Input - Next Batch\n","*   Repeat\n","\n","NOTE: First learn simple neural network in numpy\n"],"metadata":{"id":"-YctYUUfDoEm"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from keras.datasets import mnist\n","\n","# Loading MNIST dataset for 2000 train + 200 test images\n","(x_train,y_train), (x_test,y_test) = mnist.load_data()\n","x_train = x_train[:2000]\n","y = y_train[:200]\n","x_test = x_test[:2000]\n","y_test = y_test[:200]\n","\n","print(x_train.size)\n","print(type(x_train))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D61z55eeMb77","executionInfo":{"status":"ok","timestamp":1684101461921,"user_tz":-300,"elapsed":120492,"user":{"displayName":"Rashid Ali","userId":"13151374073264354904"}},"outputId":"48754b49-1b46-496e-c2cb-a39e27742093"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n","1568000\n","<class 'numpy.ndarray'>\n","Shape of convolve:  (2000, 3, 576)\n","Shape of dot-product:  (2000, 1)\n","Shape of std:  (2000, 1)\n"]}]},{"cell_type":"code","source":["\n","# print(\"Shape :: \",x_train.shape)\n","# print(\"Before\",x_train)\n","###############################x_train = x_train.T\n","# print(\"After\",x_train)\n","x = x_train/255\n","\n","y.resize((200,1))\n","####################### y = y.T\n","\n","# print(pd.Series(y[0]).value_counts())\n","# type(y)\n","# print(y.shape)\n","for i in range(y.shape[1]):\n","  if y[0][i] > 4:\n","    y[0][i] = 1\n","  else:\n","    y[0][i] = 0\n","\n","pd.Series(y[0]).value_counts()\n","\n","    ##   Intializations\n","f=np.random.uniform(size=(3,5,5))\n","\n","# plt.imshow(f[0],cmap='gray')\n","# plt.show()\n","# print(\"Original\\n\",f)\n","###########f= f.T\n","# print(f.shape)\n","# print(\"Transpose\\n\",f)\n","# print(x.shape)\n","#Breaking image for filter\n","# plt.imshow(x[4],cmap='gray')\n","# plt.show()\n","\n","    ## Samples counter\n","sample = 0\n","\n","## Convolution\n","new_image=[]\n","convolve = 0\n","for dpt_img in range(x.shape[0]): #Depth of images\n","  for dpt_fl in range(f.shape[0]): #No. of filters\n","    for i in range(x.shape[1]-f.shape[1]+1): # right move\n","      for j in range(x.shape[2]-f.shape[2]+1): # down move\n","        for k in range(f.shape[1]): # convolve next row\n","          for l in range(f.shape[2]): # convolve next element\n","            convolve += x[dpt_img][i+k][j+l] * f[dpt_fl][k][l]\n","        new_image.append(convolve)\n","\n","new_image = np.array(new_image)\n","# new_image = new_image.reshape( x.shape[0], x.shape[1]-f.shape[1]+1, x.shape[2]-f.shape[2]+1)\n","new_image = new_image.reshape( x.shape[0],f.shape[0], (x.shape[1]-f.shape[1]+1)* (x.shape[2]-f.shape[2]+1))\n","# new_image.shape\n","# plt.imshow(new_image[0],cmap='gray')\n","# plt.show()\n","print(\"Shape of convolve: \", new_image.shape)\n","\n","## Sigmoid\n","def sigmoid(x):\n","  return 1/(1+np.exp(-x))\n","def der_sigmoid(x):\n","  return x * (1-x)\n","# new_image = new_image.reshape(new_image.shape[0],(new_image.shape[1])*(new_image.shape[2]))\n","filter_sigmoid = sigmoid(new_image)\n","# new_image\n","filter_sigmoid = filter_sigmoid.reshape(filter_sigmoid.shape[0],filter_sigmoid.shape[1]*filter_sigmoid.shape[2])\n","# print(\"Shape of convolve: \", filter_sigmoid.shape)\n","\n","    ##   Intializations\n","# s_row = x.shape[1]-f.shape[1]-1\n","# s_col = x.shape[2]-f.shape[2]-1\n","input_neurons = filter_sigmoid.shape[1]\n","output_neurons = 1\n","wo = np.random.uniform(size=(input_neurons,output_neurons))\n","# wo = np.random.uniform(size=(filter_sigmoid.shape[1]))\n","# wo = wo.T\n","# wo.shape\n","\n","## Linear Transform\n","out_layer_in = np.dot(wo.T,filter_sigmoid.T)\n","out_layer_in = out_layer_in.T\n","print(\"Shape of dot-product: \", out_layer_in.shape)\n"," # looks like scaling feature values to prevent overfitting:\n","out_layer_in = (out_layer_in - np.average(out_layer_in))/np.std(out_layer_in)\n","print(\"Shape of std: \", out_layer_in.shape)\n","\n","##Sigmoid\n","output=sigmoid(out_layer_in)\n","# print(np.std(out_layer_in))\n","# print(out_layer_in)\n","# output = sigmoid(np.average(out_layer_in))\n","\n","# error = np.square(output-y[sample])/2\n","# plt.imshow(out_layer_in[0],cmap='gray')\n","# plt.show()\n","# print(output[5])\n","\n","## Back_diffs\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6WbqNCT3RWI-","executionInfo":{"status":"ok","timestamp":1684103825562,"user_tz":-300,"elapsed":115302,"user":{"displayName":"Rashid Ali","userId":"13151374073264354904"}},"outputId":"a227eee1-8dc1-4f12-9347-2b413a83d5c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of convolve:  (2000, 3, 576)\n","Shape of dot-product:  (2000, 1)\n","Shape of std:  (2000, 1)\n"]}]},{"cell_type":"code","source":["A1 = filter_sigmoid\n","error = np.square(y-output)/2\n","diff_error_output = output-y\n","diff_output_lir = output*(1-output)\n","diff_lir_wo = A1\n","# filter_sigmoid.shape\n","# wo.shape\n","lr = 0.001\n","gradient = diff_output_lir* diff_error_output\n","gradient = np.dot(gradient.T,diff_lir_wo)\n","new_weight = wo - gradient.T*lr\n","print(\"shape diff_output_lir:\", gradient.shape)\n","\n","gradient2 = np.dot(output_layer_input_wrt_filter_output_sigmoid.T, error_wrt_output * output_wrt_output_layer_input) *filter_output_sigmoid_wrt_filter_output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mdYT-UhGAf2M","executionInfo":{"status":"ok","timestamp":1662715809259,"user_tz":-300,"elapsed":389,"user":{"displayName":"Rashid Ali","userId":"13151374073264354904"}},"outputId":"713e68ed-0255-4c72-f3e0-cf5d82326819"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["shape diff_output_lir: (1, 1728)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FDJ1hyqnXqpR"},"outputs":[],"source":["\n","import cv2\n","data = []\n","labels = []\n","for j in [60]:\n","   for i in [10]:\n","      vidcap = cv2.VideoCapture(‘F:\\Machine Learning\\ML_dataset/Fold1_part1/’ +     str(j) +’/’ + str(i) + ‘.mp4’)\n","      sec = 0\n","      frameRate = 1\n","      success, image = getFrame(sec)\n","      count = 0\n","      while success and count < 240:\n","         landmarks = extract_face_landmarks(image)\n","         if sum(sum(landmarks)) != 0:\n","            count += 1\n","            data.append(landmarks)\n","            labels.append([i])\n","            sec = sec + frameRate\n","            sec = round(sec, 2)\n","            success, image = getFrame(sec)\n","            print(count)\n","         else:\n","            sec = sec + frameRate\n","            sec = round(sec, 2)\n","            success, image = getFrame(sec)\n","            print(“not detected”)\n","cap.release()\n","cv.destroyAllWindows()"]},{"cell_type":"code","source":["import pandas\n","from sklearn import linear_model\n","\n","df = pandas.read_csv(\"data.csv\")\n","\n","X = df[['Weight', 'Volume']]\n","y = df['CO2']\n","\n","regr = linear_model.LinearRegression()\n","regr.fit(X, y)\n","\n","#predict the CO2 emission of a car where the weight is 2300kg, and the volume is 1300cm3:\n","predictedCO2 = regr.predict([[2300, 1300]])\n","\n","print(predictedCO2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9MmPu69dhzOd","executionInfo":{"status":"ok","timestamp":1662027355208,"user_tz":-300,"elapsed":505,"user":{"displayName":"Rashid Ali","userId":"13151374073264354904"}},"outputId":"0156e496-b53d-431a-a53d-f5ff780111cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[107.2087328]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]}]},{"cell_type":"markdown","source":["**SVM MACHINE IMAGE CLASSIFICATION**"],"metadata":{"id":"CHP0JoKkzxoV"}},{"cell_type":"code","source":["from pathlib import Path\n","import matplotlib.pyplot as plt\n","import numpy as np\n","%matplotlib notebook\n","from sklearn import svm, metrics, datasets\n","from sklearn.utils import Bunch\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","\n","from skimage.io import imread\n","from skimage.transform import resize\n","\n","def load_image_files(container_path, dimension=(64, 64, 4)):\n","    \"\"\"\n","    Load image files with categories as subfolder names\n","    which performs like scikit-learn sample dataset\n","\n","    Parameters\n","    ----------\n","    container_path : string or unicode\n","        Path to the main folder holding one subfolder per category\n","    dimension : tuple\n","        size to which image are adjusted to\n","\n","    Returns\n","    -------\n","    Bunch\n","    \"\"\"\n","    image_dir = Path(container_path)\n","    folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]\n","    categories = [fo.name for fo in folders]\n","\n","    descr = \"A image classification dataset\"\n","    images = []\n","    flat_data = []\n","    target = []\n","    # target_names = []\n","    for i, direc in enumerate(folders):\n","        for file in direc.iterdir():\n","            img = imread(file)\n","            # print(img.shape)\n","            img_resized = resize(img, dimension, anti_aliasing=True, mode='reflect')\n","            flat_data.append(img_resized.flatten())\n","            # plt.imshow(img_resized)\n","            # plt.show(img)\n","            images.append(img_resized)\n","            target.append(i)\n","            # target_names.append(categories[i])\n","    flat_data = np.array(flat_data)\n","    target = np.array(target)\n","    img = np.array(images)\n","    return Bunch(data=flat_data,\n","                    target=target,\n","                    target_names=categories,\n","                    images=images,\n","                    DESCR=descr)\n","image_dataset = load_image_files(\"/content/drive/MyDrive/Colab Notebooks/images/\")\n"],"metadata":{"id":"iHtSTnsNBsqY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### SVM Model\n","X_train, X_test, y_train, y_test = train_test_split(image_dataset.data, image_dataset.target, test_size=0.3,random_state=100)\n","# X_train.shape\n","# image_dataset.data\n","# {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n","param_grid = [{'C': [5, 1, 10, 20, 30], 'gamma': [0.01, 0.1, 0.001, 0.0001, 0.00001], 'kernel': ['rbf']},]\n","svc = svm.SVC()\n","clf = GridSearchCV(svc, param_grid)\n","clf.fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n","print(\"Classification report for - \\n{}:\\n{}\\n\".format(clf, metrics.classification_report(y_test, y_pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7GWygroNwaTx","executionInfo":{"status":"ok","timestamp":1664179573344,"user_tz":-300,"elapsed":9465,"user":{"displayName":"Rashid Ali","userId":"13151374073264354904"}},"outputId":"e0816f1d-8559-4916-c29e-9851360da887"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Classification report for - \n","GridSearchCV(estimator=SVC(),\n","             param_grid=[{'C': [5, 1, 10, 20, 30],\n","                          'gamma': [0.01, 0.1, 0.001, 0.0001, 1e-05],\n","                          'kernel': ['rbf']}]):\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.41      0.58        17\n","           1       0.67      1.00      0.80        20\n","\n","    accuracy                           0.73        37\n","   macro avg       0.83      0.71      0.69        37\n","weighted avg       0.82      0.73      0.70        37\n","\n","\n"]}]},{"cell_type":"code","source":["### Deployment code\n","print(\"BestParameters: \", clf.best_params_)\n","my_img = imread('/content/drive/MyDrive/Colab Notebooks/test_images/pizza_1.jpg')\n","my_img_resized = resize(my_img, (64,64), anti_aliasing=True, mode='reflect')\n","print(my_img_resized.shape)\n","my_flat_data = my_img_resized.flatten()\n","my_flat_data.shape\n","my_X = np.array(my_flat_data)\n","my_X.resize(1,my_X.shape[0])\n","print(my_X.shape)\n","my_pred = clf.predict(my_X)\n","print(my_pred)\n","predic = image_dataset.target_names[my_pred[0]]\n","plt.show()\n","print(\"Truth: \", \"Pizza\")\n","print(\"Prediction: \", predic)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XTBdsVNbvQGa","executionInfo":{"status":"ok","timestamp":1663929011859,"user_tz":-300,"elapsed":347,"user":{"displayName":"Rashid Ali","userId":"13151374073264354904"}},"outputId":"93b1049d-6cb6-4755-a3ad-fec3acc13cb9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BestParameters:  {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n","(64, 64, 3)\n","(1, 12288)\n","[2]\n","Truth:  Pizza\n","Prediction:  pizza\n"]}]},{"cell_type":"code","source":["ls = [2,4,6,8]\n","ls[2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c2PVmMgDngLj","executionInfo":{"status":"ok","timestamp":1663756562688,"user_tz":-300,"elapsed":378,"user":{"displayName":"Rashid Ali","userId":"13151374073264354904"}},"outputId":"da579785-b62e-4ae8-a7f4-c1226fe1df9f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["**TESTING**"],"metadata":{"id":"w9G-DR5h_w5L"}},{"cell_type":"code","source":[],"metadata":{"id":"4-YnDS0d_vse"},"execution_count":null,"outputs":[]}]}